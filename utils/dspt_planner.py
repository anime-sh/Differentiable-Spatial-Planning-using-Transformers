# -*- coding: utf-8 -*-
"""DSPT Planner

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1n_e0a452BACcg5p2TeJwSRpFd0aKLUK6
"""

!pip install wandb -qqq
!pip install pytorch-lightning

import numpy as np
import seaborn as sn
import random
import math
from torch import autograd,Tensor
import matplotlib.pyplot as plt
from torch.types import Device
from tqdm import tqdm
import argparse
import copy
import sklearn
import wandb

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader
from torch.optim.lr_scheduler import StepLR
from torch.utils.data import TensorDataset, RandomSampler, SequentialSampler, random_split, DataLoader, IterableDataset, ConcatDataset
import torch.utils
import torch.utils.checkpoint

import pytorch_lightning as pl
from pytorch_lightning.loggers import WandbLogger
from pytorch_lightning import seed_everything
from pytorch_lightning.callbacks import LearningRateMonitor
from pytorch_lightning.callbacks import ModelCheckpoint

from google.colab import drive
drive.mount('/content/drive')

MAP_SIZE = 15
MODEL_SAVE_PATH = "/content/drive/MyDrive/DPST-MLRC/Planner/dspt"
CHECKPOINT_FOLDER = "/content/drive/MyDrive/DPST-MLRC/Planner/checkpoints"

if MAP_SIZE == 15 :
  config = {
      "RANDOM_SEED": 42,

      "train_output_dest_path": '/content/drive/MyDrive/DPST-MLRC/synthetic_navigation_datasets/trainy15.npz',
      "train_input_dest_path": '/content/drive/MyDrive/DPST-MLRC/synthetic_navigation_datasets/trainx15.npz',

      "test_output_dest_path": '/content/drive/MyDrive/DPST-MLRC/synthetic_navigation_datasets/testy15.npz',
      "test_input_dest_path": '/content/drive/MyDrive/DPST-MLRC/synthetic_navigation_datasets/testx15.npz',

      "val_output_dest_path": '/content/drive/MyDrive/DPST-MLRC/synthetic_navigation_datasets/valy15.npz',
      "val_input_dest_path": '/content/drive/MyDrive/DPST-MLRC/synthetic_navigation_datasets/valx15.npz',

      "batch_size": 20,
      "epochs": 40,
      "learning_rate": 1,

      "train_dataset_size": 100000,
      "test_dataset_size": 5000,
      "val_dataset_size": 5000,
  }
elif MAP_SIZE == 30 :
  config = {
      "RANDOM_SEED": 42,

      "train_output_dest_path": '/content/drive/MyDrive/DPST-MLRC/synthetic_navigation_datasets/trainy30.npz',
      "train_input_dest_path": '/content/drive/MyDrive/DPST-MLRC/synthetic_navigation_datasets/trainx30.npz',

      "test_output_dest_path": '/content/drive/MyDrive/DPST-MLRC/synthetic_navigation_datasets/testy30.npz',
      "test_input_dest_path": '/content/drive/MyDrive/DPST-MLRC/synthetic_navigation_datasets/testx30.npz',

      "val_output_dest_path": '/content/drive/MyDrive/DPST-MLRC/synthetic_navigation_datasets/valy30.npz',
      "val_input_dest_path": '/content/drive/MyDrive/DPST-MLRC/synthetic_navigation_datasets/valx30.npz',

      "batch_size": 20,
      "epochs": 40,
      "learning_rate": 1,

      "train_dataset_size": 100000,
      "test_dataset_size": 5000,
      "val_dataset_size": 5000,
  }
elif MAP_SIZE == 50 :
  config = {
      "RANDOM_SEED": 42,

      "train_output_dest_path": '/content/drive/MyDrive/DPST-MLRC/synthetic_navigation_datasets/trainy50.npz',
      "train_input_dest_path": '/content/drive/MyDrive/DPST-MLRC/synthetic_navigation_datasets/trainx50.npz',

      "test_output_dest_path": '/content/drive/MyDrive/DPST-MLRC/synthetic_navigation_datasets/testy50.npz',
      "test_input_dest_path": '/content/drive/MyDrive/DPST-MLRC/synthetic_navigation_datasets/testx50.npz',

      "val_output_dest_path": '/content/drive/MyDrive/DPST-MLRC/synthetic_navigation_datasets/valy50.npz',
      "val_input_dest_path": '/content/drive/MyDrive/DPST-MLRC/synthetic_navigation_datasets/valx50.npz',

      "batch_size": 2, #we'll use gradient accumulation for the 50 X 50 maps
      "epochs": 40,
      "learning_rate": 1,

      "train_dataset_size": 100000,
      "test_dataset_size": 5000,
      "val_dataset_size": 5000,
  }

lr_monitor = LearningRateMonitor(logging_interval='step')
device = torch.device("cpu")

def random_seed(seed_value, use_cuda):
    pl.seed_everything(seed_value)
    if use_cuda:
        torch.backends.cudnn.deterministic = True
        torch.backends.cudnn.benchmark = False

class Dataset():
    def __init__(self, x_file, y_file, dataset_size, train=False, batch_size=20):
        self.x_file = x_file
        self.y_file = y_file
        self.dataset_size = dataset_size
        self.batch_size = batch_size
        self.train = train
        print("Loading data...")
        self.inputs, self.labels = self.process_data()
        self.DataLoader = self.get_dataloader(self.inputs, self.labels)
        print("Data loaded")
    
    def process_data(self):
        np_x = np.load(self.x_file)
        np_y = np.load(self.y_file)

        self.x_list = np.array([np_x[i] for i in np_x.files])
        self.y_list = np.array([np_y[i] for i in np_y.files])

        return torch.Tensor(self.x_list), torch.Tensor(self.y_list)

    def get_dataloader(self, inputs, labels, train=True):
        data = TensorDataset(inputs, labels)
        if self.train:
            sampler = RandomSampler(data)
        else:
            sampler = SequentialSampler(data)
        return DataLoader(data, sampler=sampler, batch_size=self.batch_size)

class PositionalEncoding(nn.Module):

  def __init__(self,d_model=64,max_len=2500):
    super().__init__()
    pe = torch.zeros(1,d_model,max_len)
    position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(0)
    div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(max_len) / d_model)).unsqueeze(1)
    pe[0,0::2,:] = torch.sin(torch.matmul(div_term,position))
    pe[0,1::2,:] = torch.cos(torch.matmul(div_term,position))
    self.register_buffer('pe',pe)
  
  def forward(self,x,d_model=64,max_len=2500):
    x = x.to(device) + self.pe[:x.size(0)].to(device)
    return x

class CNNEncoding(nn.Module):

  def __init__(self):
    super().__init__()

    self.conv1 = nn.Conv2d(in_channels=2, out_channels=64, kernel_size=1)
    self.conv2 = nn.Conv2d(in_channels = 64,out_channels=64, kernel_size=1)
    self.flatten = nn.Flatten(start_dim=2)

  def init_weights(self) -> None:
    nn.init.kaiming_uniform_(self.conv1.weight.data,nonlinearity='relu')
    nn.init.kaiming_uniform_(self.conv2.weight.data,nonlinearity='relu')

  def forward(self,x) -> Tensor:
    x = F.relu(self.conv1(x))
    x = self.conv2(x)
    x = self.flatten(x)
    
    return x

class DSPT(nn.Module):
  def __init__(self,d_model=64,nhead=8,d_hid=512,nlayers=5,dropout=0.1):
    super().__init__()
    self.model_type = 'DSPT'
    self.pos_encoder = PositionalEncoding(max_len = MAP_SIZE**2)
    self.conv_encoder = CNNEncoding()
    encoder_layers = nn.TransformerEncoderLayer(d_model,nhead,d_hid,dropout,batch_first=True)
    self.transformer_encoder = nn.TransformerEncoder(encoder_layers,nlayers)
    self.d_model = d_model
    self.decoder = nn.Linear(d_model,1)

  def init_weights(self) -> None:
    nn.init.kaiming_uniform_(self.encoder.weight.data,nonlinearity='relu')
    self.decoder.bias.data.zero_()
    nn.init.kaiming_uniform_(self.decoder.weight.data,nonlinearity='relu')

  def forward(self, src) -> Tensor:
    src = self.conv_encoder(src)
    src = self.pos_encoder(src)
    src = torch.transpose(src,1,2)
    output = self.transformer_encoder(src)
    output = self.decoder(output)

    return output

def custom_accuracy(pred,truth,map_dim=MAP_SIZE):
  obstacles=[]
  for i in range(map_dim-1):
    for j in range(map_dim-1):
      if (truth.to('cpu').numpy()[i,j]==-1):
        obstacles.append([i,j])
  truth_map = dist_to_action(obstacles,truth.to('cpu').numpy(),map_dim)
  pred_map = dist_to_action(obstacles,pred.to('cpu').numpy(),map_dim)
  
  correct=0
  free_space=0
  for i in range(map_dim):
    for j in range(map_dim):
      a,b,c,d = truth_map[i,j]
      e,f,g,h = pred_map[i,j]
      if (truth.to('cpu').numpy()[i,j]!=-1):
        free_space = free_space+1
        if (a==e==1) or (b==f==1) or (c==g==1) or (d==h==1):
          correct = correct+1
  return correct*100/free_space

def dist_to_action(obstacles,truth,map_dim=MAP_SIZE):
  map = np.zeros((map_dim,map_dim,4))
  for i in range(map_dim-1):
    for j in range(map_dim-1):
      a=1e9
      b=1e9
      c=1e9
      d=1e9
      
      if(truth[i-1][j]):
        a=truth[i-1][j]
      if(truth[i+1][j]):
        b=truth[i+1][j]
      if(truth[i][j+1]):
        c=truth[i][j+1]
      if(truth[i][j-1]):
        d=truth[i][j-1]

      for cood in obstacles:
        if([i-1,j]==cood):
          a=1e9
        if([i+1,j]==cood):
          b=1e9
        if([i,j+1]==cood):
          c=1e9
        if([i,j-1]==cood):
          d=1e9
      map[i,j,:]=-1
      mini = min(min(a,b),min(c,d))
      if(a==mini):
        map[i,j,0] = 1
      if(b==mini):
        map[i,j,1] = 1
      if(c==mini):
        map[i,j,2] = 1
      if(d==mini):
        map[i,j,3] = 1

  return map

class WrappedModel(pl.LightningModule):
    def __init__(self, config):
        super().__init__()
        self.config = config
        self.model = DSPT()
        self.criterion = nn.MSELoss()
        print("Init Done")

    def train_dataloader(self):
        train_dataset = Dataset(x_file=self.config['train_input_dest_path'], y_file=self.config['train_output_dest_path'],
                                dataset_size=self.config['train_dataset_size'], batch_size=self.config['batch_size'], train=True)
        print("Train DataLoader Done")
        return train_dataset.DataLoader

    def val_dataloader(self):
        val_dataset = Dataset(x_file=self.config['val_input_dest_path'], y_file=self.config['val_output_dest_path'],
                              dataset_size=self.config['val_dataset_size'], batch_size=self.config['batch_size'], train=False)
        print("Validation DataLoader Done")
        return val_dataset.DataLoader

    def test_dataloader(self):
        test_dataset = Dataset(x_file=self.config['test_input_dest_path'], y_file=self.config['test_output_dest_path'],
                               dataset_size=self.config['test_dataset_size'], batch_size=1, train=False)
        print("Test DataLoader Done")
        return test_dataset.DataLoader

    def forward(self, x):
        return self.model(x)

    def on_train_start(self):
        self.logger.log_hyperparams(self.config)

    def configure_optimizers(self):
        optimizer = torch.optim.SGD(self.parameters(), lr=self.config["learning_rate"])
        return {
        "optimizer": optimizer,
        "lr_scheduler": {
            "scheduler": StepLR(optimizer, step_size=1, gamma=0.9),
        },
    }

    def training_step(self, batch, batch_idx):
        x, y = batch
        y_hat = self(x)
        y_hat=torch.reshape(y_hat, (-1, MAP_SIZE, MAP_SIZE))
        loss = self.criterion(y_hat, y)
        self.log("train_loss", loss)
        return loss

    def validation_step(self, batch, batch_idx):
        x, y = batch
        y_hat = self(x)
        y_hat=torch.reshape(y_hat, ( -1,MAP_SIZE, MAP_SIZE))
        loss = self.criterion(y_hat, y)
        self.log("val_loss", loss, on_step=False, on_epoch=True)
        return loss

    def test_step(self, batch, batch_idx):
        x, y = batch
        y_hat = self(x)
        y_hat=torch.reshape(y_hat, ( MAP_SIZE, MAP_SIZE))
        loss = self.criterion(y_hat, y)

        acc = custom_accuracy(torch.reshape(y_hat,( MAP_SIZE, MAP_SIZE)),torch.reshape( y,( MAP_SIZE, MAP_SIZE)))
        self.log("test_loss", loss, on_step=True, on_epoch=True)
        self.log("test_acc", acc, on_step=True, on_epoch=True)
        output = y_hat.to('cpu').detach().numpy()
        input = torch.reshape( y,( MAP_SIZE, MAP_SIZE)).to('cpu').detach().numpy()
        fig, axarr = plt.subplots(2)
        axarr[0].imshow(input, cmap='hot', interpolation='nearest')
        axarr[1].imshow(output, cmap='hot', interpolation='nearest')
        fig.suptitle("Accuracy = "+str(acc))
        axarr[0].set_title('Ground Truth')
        axarr[1].set_title('Predicted Output')
        fig.savefig('temp.png')
        plt.close(fig)
        wandb_logger.log_image("test_samples",images=["temp.png"])
        return loss

plt.rcParams['figure.figsize'] = [15, 8]
plt.rcParams.update({'font.size': 8})
device = torch.device(
    "cuda:0") if torch.cuda.is_available() else torch.device("cpu")
print("Device:", device)
random_seed(config["RANDOM_SEED"], True)
wandb_logger = WandbLogger(
    project="DSPT Planner M = "+str(MAP_SIZE), entity="agv_astar_dspt")
model = WrappedModel(config)
checkpoint_callback = ModelCheckpoint(
    monitor="val_loss",
    dirpath=CHECKPOINT_FOLDER,
    filename="planner-intermediate-"+str(MAP_SIZE)+"-{epoch:02d}-{val_loss:.2f}",
    save_top_k=1,
    mode="min",
)
trainer = pl.Trainer(
    default_root_dir=CHECKPOINT_FOLDER,
    max_epochs=config["epochs"],
    gpus=1,
    logger=wandb_logger,
    gradient_clip_val=1.0,
    callbacks=[lr_monitor,checkpoint_callback],
    accumulate_grad_batches = 10
)
# trainer.fit(model)
# trainer.test(model)
# trainer.save_checkpoint(MODEL_SAVE_PATH+str(MAP_SIZE)+".ckpt")
wandb.finish()

model = WrappedModel.load_from_checkpoint(MODEL_SAVE_PATH+str(MAP_SIZE)+".ckpt",config = config)
trainer.test(model)

drive.flush_and_unmount()
print('All changes made in this colab session should now be visible in Drive.')