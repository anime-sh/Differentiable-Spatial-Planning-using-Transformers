{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":28829,"status":"ok","timestamp":1643468821322,"user":{"displayName":"Arnesh Issar","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09452993506379549591"},"user_tz":-330},"id":"Y8rKW6KHgaxv","outputId":"57bc2b11-9256-4c7a-f394-cd44cd4d344a"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[K     |████████████████████████████████| 1.7 MB 7.5 MB/s \n","\u001b[K     |████████████████████████████████| 97 kB 6.8 MB/s \n","\u001b[K     |████████████████████████████████| 143 kB 49.7 MB/s \n","\u001b[K     |████████████████████████████████| 180 kB 50.7 MB/s \n","\u001b[K     |████████████████████████████████| 63 kB 1.7 MB/s \n","\u001b[?25h  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting pytorch-lightning\n","  Downloading pytorch_lightning-1.5.9-py3-none-any.whl (527 kB)\n","\u001b[K     |████████████████████████████████| 527 kB 8.7 MB/s \n","\u001b[?25hCollecting future>=0.17.1\n","  Downloading future-0.18.2.tar.gz (829 kB)\n","\u001b[K     |████████████████████████████████| 829 kB 46.1 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (4.62.3)\n","Collecting pyDeprecate==0.3.1\n","  Downloading pyDeprecate-0.3.1-py3-none-any.whl (10 kB)\n","Collecting fsspec[http]!=2021.06.0,>=2021.05.0\n","  Downloading fsspec-2022.1.0-py3-none-any.whl (133 kB)\n","\u001b[K     |████████████████████████████████| 133 kB 51.2 MB/s \n","\u001b[?25hRequirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (21.3)\n","Requirement already satisfied: tensorboard>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (2.7.0)\n","Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (1.19.5)\n","Collecting setuptools==59.5.0\n","  Downloading setuptools-59.5.0-py3-none-any.whl (952 kB)\n","\u001b[K     |████████████████████████████████| 952 kB 55.8 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (3.10.0.2)\n","Collecting PyYAML>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 65.2 MB/s \n","\u001b[?25hCollecting torchmetrics>=0.4.1\n","  Downloading torchmetrics-0.7.0-py3-none-any.whl (396 kB)\n","\u001b[K     |████████████████████████████████| 396 kB 59.4 MB/s \n","\u001b[?25hRequirement already satisfied: torch>=1.7.* in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (1.10.0+cu111)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (2.23.0)\n","Collecting aiohttp\n","  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n","\u001b[K     |████████████████████████████████| 1.1 MB 41.0 MB/s \n","\u001b[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=17.0->pytorch-lightning) (3.0.7)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.0.1)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (0.37.1)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.35.0)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.8.1)\n","Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (3.17.3)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.0.0)\n","Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.43.0)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (0.6.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (3.3.6)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (0.4.6)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py>=0.4->tensorboard>=2.2.0->pytorch-lightning) (1.15.0)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (4.2.4)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (0.2.8)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (4.8)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning) (1.3.0)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning) (4.10.1)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning) (3.7.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (0.4.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (2021.10.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning) (3.1.1)\n","Collecting asynctest==0.13.0\n","  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n","Collecting multidict<7.0,>=4.5\n","  Downloading multidict-6.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n","\u001b[K     |████████████████████████████████| 94 kB 424 kB/s \n","\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (21.4.0)\n","Collecting frozenlist>=1.1.1\n","  Downloading frozenlist-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n","\u001b[K     |████████████████████████████████| 144 kB 38.1 MB/s \n","\u001b[?25hCollecting aiosignal>=1.1.2\n","  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n","Collecting yarl<2.0,>=1.0\n","  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n","\u001b[K     |████████████████████████████████| 271 kB 37.9 MB/s \n","\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3\n","  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n","Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (2.0.10)\n","Building wheels for collected packages: future\n","  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491070 sha256=3cdc70113f44a029d72644d36f52ccb8e2229dda8a05f1ed1cd71eef37de0e34\n","  Stored in directory: /root/.cache/pip/wheels/56/b0/fe/4410d17b32f1f0c3cf54cdfb2bc04d7b4b8f4ae377e2229ba0\n","Successfully built future\n","Installing collected packages: setuptools, multidict, frozenlist, yarl, asynctest, async-timeout, aiosignal, pyDeprecate, fsspec, aiohttp, torchmetrics, PyYAML, future, pytorch-lightning\n","  Attempting uninstall: setuptools\n","    Found existing installation: setuptools 57.4.0\n","    Uninstalling setuptools-57.4.0:\n","      Successfully uninstalled setuptools-57.4.0\n","  Attempting uninstall: PyYAML\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","  Attempting uninstall: future\n","    Found existing installation: future 0.16.0\n","    Uninstalling future-0.16.0:\n","      Successfully uninstalled future-0.16.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n","Successfully installed PyYAML-6.0 aiohttp-3.8.1 aiosignal-1.2.0 async-timeout-4.0.2 asynctest-0.13.0 frozenlist-1.3.0 fsspec-2022.1.0 future-0.18.2 multidict-6.0.2 pyDeprecate-0.3.1 pytorch-lightning-1.5.9 setuptools-59.5.0 torchmetrics-0.7.0 yarl-1.7.2\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["pkg_resources"]}}},"metadata":{}}],"source":["!pip install wandb -qqq\n","!pip install pytorch-lightning"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CuKcesfxfxOY"},"outputs":[],"source":["import numpy as np\n","import seaborn as sn\n","import random\n","import math\n","from torch import autograd,Tensor\n","import matplotlib.pyplot as plt\n","from torch.types import Device\n","from tqdm import tqdm\n","import argparse\n","import copy\n","import sklearn\n","import wandb\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader\n","from torch.optim.lr_scheduler import StepLR\n","from torch.utils.data import TensorDataset, RandomSampler, SequentialSampler, random_split, DataLoader, IterableDataset, ConcatDataset\n","import torch.utils\n","import torch.utils.checkpoint\n","\n","import pytorch_lightning as pl\n","from pytorch_lightning.loggers import WandbLogger\n","from pytorch_lightning import seed_everything\n","from pytorch_lightning.callbacks import LearningRateMonitor\n","from pytorch_lightning.callbacks import ModelCheckpoint"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vGLClg9fiL8x","executionInfo":{"status":"ok","timestamp":1643468860861,"user_tz":-330,"elapsed":32936,"user":{"displayName":"Arnesh Issar","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09452993506379549591"}},"outputId":"a9036f2a-b485-40ca-ab51-9e9ceef2d9b0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oBONv9ybj4qU"},"outputs":[],"source":["MAP_SIZE = 15\n","MODEL_SAVE_PATH = \"/content/drive/MyDrive/DPST-MLRC/Planner/dspt\"\n","CHECKPOINT_FOLDER = \"/content/drive/MyDrive/DPST-MLRC/Planner/checkpoints\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mzfr1ThKj4ws"},"outputs":[],"source":["if MAP_SIZE == 15 :\n","  config = {\n","      \"RANDOM_SEED\": 42,\n","\n","      \"train_output_dest_path\": '/content/drive/MyDrive/DPST-MLRC/synthetic_navigation_datasets/trainy15.npz',\n","      \"train_input_dest_path\": '/content/drive/MyDrive/DPST-MLRC/synthetic_navigation_datasets/trainx15.npz',\n","\n","      \"test_output_dest_path\": '/content/drive/MyDrive/DPST-MLRC/synthetic_navigation_datasets/testy15.npz',\n","      \"test_input_dest_path\": '/content/drive/MyDrive/DPST-MLRC/synthetic_navigation_datasets/testx15.npz',\n","\n","      \"val_output_dest_path\": '/content/drive/MyDrive/DPST-MLRC/synthetic_navigation_datasets/valy15.npz',\n","      \"val_input_dest_path\": '/content/drive/MyDrive/DPST-MLRC/synthetic_navigation_datasets/valx15.npz',\n","\n","      \"batch_size\": 20,\n","      \"epochs\": 40,\n","      \"learning_rate\": 1,\n","\n","      \"train_dataset_size\": 100000,\n","      \"test_dataset_size\": 5000,\n","      \"val_dataset_size\": 5000,\n","  }\n","elif MAP_SIZE == 30 :\n","  config = {\n","      \"RANDOM_SEED\": 42,\n","\n","      \"train_output_dest_path\": '/content/drive/MyDrive/DPST-MLRC/synthetic_navigation_datasets/trainy30.npz',\n","      \"train_input_dest_path\": '/content/drive/MyDrive/DPST-MLRC/synthetic_navigation_datasets/trainx30.npz',\n","\n","      \"test_output_dest_path\": '/content/drive/MyDrive/DPST-MLRC/synthetic_navigation_datasets/testy30.npz',\n","      \"test_input_dest_path\": '/content/drive/MyDrive/DPST-MLRC/synthetic_navigation_datasets/testx30.npz',\n","\n","      \"val_output_dest_path\": '/content/drive/MyDrive/DPST-MLRC/synthetic_navigation_datasets/valy30.npz',\n","      \"val_input_dest_path\": '/content/drive/MyDrive/DPST-MLRC/synthetic_navigation_datasets/valx30.npz',\n","\n","      \"batch_size\": 20,\n","      \"epochs\": 40,\n","      \"learning_rate\": 1,\n","\n","      \"train_dataset_size\": 100000,\n","      \"test_dataset_size\": 5000,\n","      \"val_dataset_size\": 5000,\n","  }\n","elif MAP_SIZE == 50 :\n","  config = {\n","      \"RANDOM_SEED\": 42,\n","\n","      \"train_output_dest_path\": '/content/drive/MyDrive/DPST-MLRC/synthetic_navigation_datasets/trainy50.npz',\n","      \"train_input_dest_path\": '/content/drive/MyDrive/DPST-MLRC/synthetic_navigation_datasets/trainx50.npz',\n","\n","      \"test_output_dest_path\": '/content/drive/MyDrive/DPST-MLRC/synthetic_navigation_datasets/testy50.npz',\n","      \"test_input_dest_path\": '/content/drive/MyDrive/DPST-MLRC/synthetic_navigation_datasets/testx50.npz',\n","\n","      \"val_output_dest_path\": '/content/drive/MyDrive/DPST-MLRC/synthetic_navigation_datasets/valy50.npz',\n","      \"val_input_dest_path\": '/content/drive/MyDrive/DPST-MLRC/synthetic_navigation_datasets/valx50.npz',\n","\n","      \"batch_size\": 2, #we'll use gradient accumulation for the 50 X 50 maps\n","      \"epochs\": 40,\n","      \"learning_rate\": 1,\n","\n","      \"train_dataset_size\": 100000,\n","      \"test_dataset_size\": 5000,\n","      \"val_dataset_size\": 5000,\n","  }\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fjreacBsf5Ic"},"outputs":[],"source":["lr_monitor = LearningRateMonitor(logging_interval='step')\n","device = torch.device(\"cpu\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ki4UQadLf5LM"},"outputs":[],"source":["def random_seed(seed_value, use_cuda):\n","    pl.seed_everything(seed_value)\n","    if use_cuda:\n","        torch.backends.cudnn.deterministic = True\n","        torch.backends.cudnn.benchmark = False"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PGJCFTmjf5N5"},"outputs":[],"source":["class Dataset():\n","    def __init__(self, x_file, y_file, dataset_size, train=False, batch_size=20):\n","        self.x_file = x_file\n","        self.y_file = y_file\n","        self.dataset_size = dataset_size\n","        self.batch_size = batch_size\n","        self.train = train\n","        print(\"Loading data...\")\n","        self.inputs, self.labels = self.process_data()\n","        self.DataLoader = self.get_dataloader(self.inputs, self.labels)\n","        print(\"Data loaded\")\n","    \n","    def process_data(self):\n","        np_x = np.load(self.x_file)\n","        np_y = np.load(self.y_file)\n","\n","        self.x_list = np.array([np_x[i] for i in np_x.files])\n","        self.y_list = np.array([np_y[i] for i in np_y.files])\n","\n","        return torch.Tensor(self.x_list), torch.Tensor(self.y_list)\n","\n","    def get_dataloader(self, inputs, labels, train=True):\n","        data = TensorDataset(inputs, labels)\n","        if self.train:\n","            sampler = RandomSampler(data)\n","        else:\n","            sampler = SequentialSampler(data)\n","        return DataLoader(data, sampler=sampler, batch_size=self.batch_size)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mCf226Jof5Qq"},"outputs":[],"source":["class PositionalEncoding(nn.Module):\n","\n","  def __init__(self,d_model=64,max_len=2500):\n","    super().__init__()\n","    pe = torch.zeros(1,d_model,max_len)\n","    position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(0)\n","    div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(max_len) / d_model)).unsqueeze(1)\n","    pe[0,0::2,:] = torch.sin(torch.matmul(div_term,position))\n","    pe[0,1::2,:] = torch.cos(torch.matmul(div_term,position))\n","    self.register_buffer('pe',pe)\n","  \n","  def forward(self,x,d_model=64,max_len=2500):\n","    x = x.to(device) + self.pe[:x.size(0)].to(device)\n","    return x\n","\n","class CNNEncoding(nn.Module):\n","\n","  def __init__(self):\n","    super().__init__()\n","\n","    self.conv1 = nn.Conv2d(in_channels=2, out_channels=64, kernel_size=1)\n","    self.conv2 = nn.Conv2d(in_channels = 64,out_channels=64, kernel_size=1)\n","    self.flatten = nn.Flatten(start_dim=2)\n","\n","  def init_weights(self) -> None:\n","    nn.init.kaiming_uniform_(self.conv1.weight.data,nonlinearity='relu')\n","    nn.init.kaiming_uniform_(self.conv2.weight.data,nonlinearity='relu')\n","\n","  def forward(self,x) -> Tensor:\n","    x = F.relu(self.conv1(x))\n","    x = self.conv2(x)\n","    x = self.flatten(x)\n","    \n","    return x\n","\n","class DSPT(nn.Module):\n","  def __init__(self,d_model=64,nhead=8,d_hid=512,nlayers=5,dropout=0.1):\n","    super().__init__()\n","    self.model_type = 'DSPT'\n","    self.pos_encoder = PositionalEncoding(max_len = MAP_SIZE**2)\n","    self.conv_encoder = CNNEncoding()\n","    encoder_layers = nn.TransformerEncoderLayer(d_model,nhead,d_hid,dropout,batch_first=True)\n","    self.transformer_encoder = nn.TransformerEncoder(encoder_layers,nlayers)\n","    self.d_model = d_model\n","    self.decoder = nn.Linear(d_model,1)\n","\n","  def init_weights(self) -> None:\n","    nn.init.kaiming_uniform_(self.encoder.weight.data,nonlinearity='relu')\n","    self.decoder.bias.data.zero_()\n","    nn.init.kaiming_uniform_(self.decoder.weight.data,nonlinearity='relu')\n","\n","  def forward(self, src) -> Tensor:\n","    src = self.conv_encoder(src)\n","    src = self.pos_encoder(src)\n","    src = torch.transpose(src,1,2)\n","    output = self.transformer_encoder(src)\n","    output = self.decoder(output)\n","\n","    return output\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"g2zboGbdf5TF"},"outputs":[],"source":["def custom_accuracy(pred,truth,map_dim=MAP_SIZE):\n","  obstacles=[]\n","  for i in range(map_dim-1):\n","    for j in range(map_dim-1):\n","      if (truth.to('cpu').numpy()[i,j]==-1):\n","        obstacles.append([i,j])\n","  truth_map = dist_to_action(obstacles,truth.to('cpu').numpy(),map_dim)\n","  pred_map = dist_to_action(obstacles,pred.to('cpu').numpy(),map_dim)\n","  \n","  correct=0\n","  free_space=0\n","  for i in range(map_dim):\n","    for j in range(map_dim):\n","      a,b,c,d = truth_map[i,j]\n","      e,f,g,h = pred_map[i,j]\n","      if (truth.to('cpu').numpy()[i,j]!=-1):\n","        free_space = free_space+1\n","        if (a==e==1) or (b==f==1) or (c==g==1) or (d==h==1):\n","          correct = correct+1\n","  return correct*100/free_space\n","\n","def dist_to_action(obstacles,truth,map_dim=MAP_SIZE):\n","  map = np.zeros((map_dim,map_dim,4))\n","  for i in range(map_dim-1):\n","    for j in range(map_dim-1):\n","      a=1e9\n","      b=1e9\n","      c=1e9\n","      d=1e9\n","      \n","      if(truth[i-1][j]):\n","        a=truth[i-1][j]\n","      if(truth[i+1][j]):\n","        b=truth[i+1][j]\n","      if(truth[i][j+1]):\n","        c=truth[i][j+1]\n","      if(truth[i][j-1]):\n","        d=truth[i][j-1]\n","\n","      for cood in obstacles:\n","        if([i-1,j]==cood):\n","          a=1e9\n","        if([i+1,j]==cood):\n","          b=1e9\n","        if([i,j+1]==cood):\n","          c=1e9\n","        if([i,j-1]==cood):\n","          d=1e9\n","      map[i,j,:]=-1\n","      mini = min(min(a,b),min(c,d))\n","      if(a==mini):\n","        map[i,j,0] = 1\n","      if(b==mini):\n","        map[i,j,1] = 1\n","      if(c==mini):\n","        map[i,j,2] = 1\n","      if(d==mini):\n","        map[i,j,3] = 1\n","\n","  return map"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TZjlNGaLf5WA"},"outputs":[],"source":["class WrappedModel(pl.LightningModule):\n","    def __init__(self, config):\n","        super().__init__()\n","        self.config = config\n","        self.model = DSPT()\n","        self.criterion = nn.MSELoss()\n","        print(\"Init Done\")\n","\n","    def train_dataloader(self):\n","        train_dataset = Dataset(x_file=self.config['train_input_dest_path'], y_file=self.config['train_output_dest_path'],\n","                                dataset_size=self.config['train_dataset_size'], batch_size=self.config['batch_size'], train=True)\n","        print(\"Train DataLoader Done\")\n","        return train_dataset.DataLoader\n","\n","    def val_dataloader(self):\n","        val_dataset = Dataset(x_file=self.config['val_input_dest_path'], y_file=self.config['val_output_dest_path'],\n","                              dataset_size=self.config['val_dataset_size'], batch_size=self.config['batch_size'], train=False)\n","        print(\"Validation DataLoader Done\")\n","        return val_dataset.DataLoader\n","\n","    def test_dataloader(self):\n","        test_dataset = Dataset(x_file=self.config['test_input_dest_path'], y_file=self.config['test_output_dest_path'],\n","                               dataset_size=self.config['test_dataset_size'], batch_size=1, train=False)\n","        print(\"Test DataLoader Done\")\n","        return test_dataset.DataLoader\n","\n","    def forward(self, x):\n","        return self.model(x)\n","\n","    def on_train_start(self):\n","        self.logger.log_hyperparams(self.config)\n","\n","    def configure_optimizers(self):\n","        optimizer = torch.optim.SGD(self.parameters(), lr=self.config[\"learning_rate\"])\n","        return {\n","        \"optimizer\": optimizer,\n","        \"lr_scheduler\": {\n","            \"scheduler\": StepLR(optimizer, step_size=1, gamma=0.9),\n","        },\n","    }\n","\n","    def training_step(self, batch, batch_idx):\n","        x, y = batch\n","        y_hat = self(x)\n","        y_hat=torch.reshape(y_hat, (-1, MAP_SIZE, MAP_SIZE))\n","        loss = self.criterion(y_hat, y)\n","        self.log(\"train_loss\", loss)\n","        return loss\n","\n","    def validation_step(self, batch, batch_idx):\n","        x, y = batch\n","        y_hat = self(x)\n","        y_hat=torch.reshape(y_hat, ( -1,MAP_SIZE, MAP_SIZE))\n","        loss = self.criterion(y_hat, y)\n","        self.log(\"val_loss\", loss, on_step=False, on_epoch=True)\n","        return loss\n","\n","    def test_step(self, batch, batch_idx):\n","        x, y = batch\n","        y_hat = self(x)\n","        y_hat=torch.reshape(y_hat, ( MAP_SIZE, MAP_SIZE))\n","        loss = self.criterion(y_hat, y)\n","\n","        acc = custom_accuracy(torch.reshape(y_hat,( MAP_SIZE, MAP_SIZE)),torch.reshape( y,( MAP_SIZE, MAP_SIZE)))\n","        self.log(\"test_loss\", loss, on_step=True, on_epoch=True)\n","        self.log(\"test_acc\", acc, on_step=True, on_epoch=True)\n","        output = y_hat.to('cpu').detach().numpy()\n","        input = torch.reshape( y,( MAP_SIZE, MAP_SIZE)).to('cpu').detach().numpy()\n","        fig, axarr = plt.subplots(2)\n","        axarr[0].imshow(input, cmap='hot', interpolation='nearest')\n","        axarr[1].imshow(output, cmap='hot', interpolation='nearest')\n","        fig.suptitle(\"Accuracy = \"+str(acc))\n","        axarr[0].set_title('Ground Truth')\n","        axarr[1].set_title('Predicted Output')\n","        fig.savefig('temp.png')\n","        plt.close(fig)\n","        wandb_logger.log_image(\"test_samples\",images=[\"temp.png\"])\n","        return loss"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Au457aJcf5ZL","outputId":"6d3a3dd9-67f9-4951-97f5-95c2a8238679","executionInfo":{"status":"ok","timestamp":1643468864031,"user_tz":-330,"elapsed":1392,"user":{"displayName":"Arnesh Issar","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09452993506379549591"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["Global seed set to 42\n"]},{"output_type":"stream","name":"stdout","text":["Device: cuda:0\n","Init Done\n"]},{"output_type":"stream","name":"stderr","text":["GPU available: True, used: True\n","TPU available: False, using: 0 TPU cores\n","IPU available: False, using: 0 IPUs\n"]}],"source":["plt.rcParams['figure.figsize'] = [15, 8]\n","plt.rcParams.update({'font.size': 8})\n","device = torch.device(\n","    \"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n","print(\"Device:\", device)\n","random_seed(config[\"RANDOM_SEED\"], True)\n","wandb_logger = WandbLogger(\n","    project=\"DSPT Planner M = \"+str(MAP_SIZE), entity=\"agv_astar_dspt\")\n","model = WrappedModel(config)\n","checkpoint_callback = ModelCheckpoint(\n","    monitor=\"val_loss\",\n","    dirpath=CHECKPOINT_FOLDER,\n","    filename=\"planner-intermediate-\"+str(MAP_SIZE)+\"-{epoch:02d}-{val_loss:.2f}\",\n","    save_top_k=1,\n","    mode=\"min\",\n",")\n","trainer = pl.Trainer(\n","    default_root_dir=CHECKPOINT_FOLDER,\n","    max_epochs=config[\"epochs\"],\n","    gpus=1,\n","    logger=wandb_logger,\n","    gradient_clip_val=1.0,\n","    callbacks=[lr_monitor,checkpoint_callback],\n","    accumulate_grad_batches = 10\n",")\n","# trainer.fit(model)\n","# trainer.test(model)\n","# trainer.save_checkpoint(MODEL_SAVE_PATH+str(MAP_SIZE)+\".ckpt\")\n","wandb.finish()\n","\n"]},{"cell_type":"code","source":["model = WrappedModel.load_from_checkpoint(MODEL_SAVE_PATH+str(MAP_SIZE)+\".ckpt\",config = config)\n","trainer.test(model)"],"metadata":{"id":"HfZz-9ZMVXzw","colab":{"base_uri":"https://localhost:8080/","height":316,"referenced_widgets":["f6fb682f03dc4197b0486c2f20578e84","ad5c6882e6d04348a349c8af8482783c","2ac6d134bc8c46dbbc2120688fef24b2","a5659359483a4e8d9af7d53dc1d35af5","0897eeea1a784bf88a5b8e5f8f30153c","e9b8bf78a8db4623a8eb75b52ce8375d","02354fa65acb4647bccff52eeb0f0ef3","e3b2544d5d0e4398b09577ef1ca088ee","203cd471a7b54f7981661f2c93076617","e72bee2deee0473da01eb89ad8555c56","9b9352acc52944faa941d6ba7c383c37"]},"executionInfo":{"status":"ok","timestamp":1643469027547,"user_tz":-330,"elapsed":163547,"user":{"displayName":"Arnesh Issar","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09452993506379549591"}},"outputId":"e31f81da-6083-473a-d7ef-e315000c59cd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"]},{"output_type":"stream","name":"stdout","text":["Init Done\n","Loading data...\n","Data loaded\n","Test DataLoader Done\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/data_loading.py:133: UserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 4 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n","  f\"The dataloader, {name}, does not have many workers which may be a bottleneck.\"\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f6fb682f03dc4197b0486c2f20578e84","version_minor":0,"version_major":2},"text/plain":["Testing: 0it [00:00, ?it/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([1, 15, 15])) that is different to the input size (torch.Size([15, 15])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","  return F.mse_loss(input, target, reduction=self.reduction)\n"]},{"output_type":"display_data","data":{"application/javascript":["\n","        window._wandbApiKey = new Promise((resolve, reject) => {\n","            function loadScript(url) {\n","            return new Promise(function(resolve, reject) {\n","                let newScript = document.createElement(\"script\");\n","                newScript.onerror = reject;\n","                newScript.onload = resolve;\n","                document.body.appendChild(newScript);\n","                newScript.src = url;\n","            });\n","            }\n","            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n","            const iframe = document.createElement('iframe')\n","            iframe.style.cssText = \"width:0;height:0;border:none\"\n","            document.body.appendChild(iframe)\n","            const handshake = new Postmate({\n","                container: iframe,\n","                url: 'https://wandb.ai/authorize'\n","            });\n","            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n","            handshake.then(function(child) {\n","                child.on('authorize', data => {\n","                    clearTimeout(timeout)\n","                    resolve(data)\n","                });\n","            });\n","            })\n","        });\n","    "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n","/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py:688: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n","  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aOPWkLjvf5fd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1643469029808,"user_tz":-330,"elapsed":2295,"user":{"displayName":"Arnesh Issar","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09452993506379549591"}},"outputId":"e26cc2dd-9ecd-45b3-aa59-4d80a7477942"},"outputs":[{"output_type":"stream","name":"stdout","text":["All changes made in this colab session should now be visible in Drive.\n"]}],"source":["drive.flush_and_unmount()\n","print('All changes made in this colab session should now be visible in Drive.')"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"machine_shape":"hm","name":"DSPT Planner","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"f6fb682f03dc4197b0486c2f20578e84":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_ad5c6882e6d04348a349c8af8482783c","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_2ac6d134bc8c46dbbc2120688fef24b2","IPY_MODEL_a5659359483a4e8d9af7d53dc1d35af5","IPY_MODEL_0897eeea1a784bf88a5b8e5f8f30153c"]}},"ad5c6882e6d04348a349c8af8482783c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":"row wrap","width":"100%","min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":"inline-flex","left":null}},"2ac6d134bc8c46dbbc2120688fef24b2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_e9b8bf78a8db4623a8eb75b52ce8375d","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Testing: ","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_02354fa65acb4647bccff52eeb0f0ef3"}},"a5659359483a4e8d9af7d53dc1d35af5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_e3b2544d5d0e4398b09577ef1ca088ee","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"info","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":0,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_203cd471a7b54f7981661f2c93076617"}},"0897eeea1a784bf88a5b8e5f8f30153c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_e72bee2deee0473da01eb89ad8555c56","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 0/? [00:00&lt;?, ?it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_9b9352acc52944faa941d6ba7c383c37"}},"e9b8bf78a8db4623a8eb75b52ce8375d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"02354fa65acb4647bccff52eeb0f0ef3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e3b2544d5d0e4398b09577ef1ca088ee":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"203cd471a7b54f7981661f2c93076617":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":"2","_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e72bee2deee0473da01eb89ad8555c56":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"9b9352acc52944faa941d6ba7c383c37":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"nbformat":4,"nbformat_minor":0}