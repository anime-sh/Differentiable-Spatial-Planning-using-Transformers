{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "KMz2FliW6bum",
        "outputId": "74cb1a47-ceb4-42ca-bcbd-0c3b2ca65513"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading 1lORbh70-sTXvY48ARifexxLsYepDcHSx into ./navdata_input_30.npy... Done.\n"
          ]
        }
      ],
      "source": [
        "from google_drive_downloader import GoogleDriveDownloader as gdd\n",
        "gdd.download_file_from_google_drive(file_id='1lORbh70-sTXvY48ARifexxLsYepDcHSx',\n",
        "                                    dest_path='./navdata_input_30.npy',\n",
        "                                    unzip=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "pIEQCWGd7i_4",
        "outputId": "8aba576e-1d66-4175-e597-856e0f4b702a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading 10WwaIDmBo2cfdHJz4O0aABN0mIbF8ByH into ./navdata_output_30.npy... Done.\n"
          ]
        }
      ],
      "source": [
        "from google_drive_downloader import GoogleDriveDownloader as gdd\n",
        "gdd.download_file_from_google_drive(file_id='10WwaIDmBo2cfdHJz4O0aABN0mIbF8ByH',\n",
        "                                    dest_path='./navdata_output_30.npy',\n",
        "                                    unzip=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "mhTyHGrj--o1"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch \n",
        "import torch.nn as nn \n",
        "import torch.nn.functional as F\n",
        "from torch import autograd\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import math\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "_u7itSMvajD1"
      },
      "outputs": [],
      "source": [
        "def random_seed(seed_value, use_cuda):\n",
        "    np.random.seed(seed_value)  \n",
        "    torch.manual_seed(seed_value)  \n",
        "    random.seed(seed_value)\n",
        "    if use_cuda:\n",
        "        torch.cuda.manual_seed(seed_value)\n",
        "        torch.cuda.manual_seed_all(seed_value)  \n",
        "        torch.backends.cudnn.deterministic = True\n",
        "        torch.backends.cudnn.benchmark = False\n",
        "random_seed(42, True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "-SfcsUYaCY9u"
      },
      "outputs": [],
      "source": [
        "class SyntheticNavigationDataset(Dataset):\n",
        "\n",
        "  #probably not a good idea to load 700 mb of data directly to RAM\n",
        "  #current dataset has 33000 maps ,  the paper uses 100000 \n",
        "\n",
        "  def __init__(self,x_file,y_file,n):\n",
        "    self.x_list = []\n",
        "    self.y_list = []\n",
        "    with open(x_file,'rb') as fx, open(y_file,'rb') as fy:\n",
        "      for i in range(n):\n",
        "        self.x_list.append(np.load(fx))\n",
        "        self.y_list.append(np.load(fy))\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.x_list)\n",
        "\n",
        "  def __getitem__(self,idx):\n",
        "    x_tensor = torch.from_numpy(self.x_list[idx].astype(np.float32))\n",
        "    y_tensor = torch.from_numpy(self.y_list[idx].astype(np.float32))\n",
        "    sample = {'x':x_tensor,'y':y_tensor}\n",
        "\n",
        "    return sample   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eo7KmSAyPKyZ",
        "outputId": "f284d6a5-af12-4942-b153-47b0a6868551"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         ...,\n",
            "         [0., 1., 1.,  ..., 1., 1., 0.],\n",
            "         [0., 1., 1.,  ..., 1., 1., 0.],\n",
            "         [0., 1., 1.,  ..., 1., 1., 0.]],\n",
            "\n",
            "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         ...,\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.]]])\n"
          ]
        }
      ],
      "source": [
        "nav_dataset = SyntheticNavigationDataset(x_file = './navdata_input_30.npy', y_file = './navdata_output_30.npy',n = 33000)\n",
        "sample = nav_dataset[10]\n",
        "print(sample['x'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "zGrwL7e4Pfdc",
        "outputId": "fe6a0564-a8dc-4721-9e36-7ac47620c09d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[38., 37., 36., 35., 34., 33., 32., 31., 32., 33., 34., 35., 34., 33.,\n",
            "         32., 31., 32., 33., 34., 35., 36., 37., 38., 39., 40., 41., 42., 43.,\n",
            "         44., 45.],\n",
            "        [37., 36., 35., 34., 33., 32., 31., 30., -1., -1., -1., -1., -1., -1.,\n",
            "         -1., 30., 31., 32., 33., 34., 35., 36., 37., 38., 39., 40., 41., 42.,\n",
            "         43., 44.],\n",
            "        [36., 35., 34., 33., 32., 31., 30., 29., -1., -1., -1., -1., -1., -1.,\n",
            "         28., 29., 30., 31., 32., 33., 34., 35., 36., 37., 38., 39., 40., 41.,\n",
            "         42., 43.],\n",
            "        [35., 34., 33., 32., 31., 30., 29., 28., -1., -1., -1., -1., -1., -1.,\n",
            "         27., 28., 29., 30., 31., 32., 33., 34., 35., 36., 37., 38., 39., 40.,\n",
            "         41., 42.],\n",
            "        [34., 33., 32., 31., 30., 29., 28., 27., -1., -1., -1., -1., -1., -1.,\n",
            "         26., 27., 28., 29., 30., 31., 32., 33., 34., 35., 36., 37., 38., 39.,\n",
            "         40., 41.],\n",
            "        [33., 32., 31., 30., 29., 28., 27., 26., -1., -1., -1., -1., -1., -1.,\n",
            "         25., 26., 27., 28., 29., 30., 31., 32., 33., 34., 35., 36., 37., 38.,\n",
            "         39., 40.],\n",
            "        [32., 31., 30., 29., 28., 27., 26., 25., -1., -1., -1., -1., -1., -1.,\n",
            "         24., 25., 26., 27., 28., 29., 30., 31., 32., 33., 34., 35., 36., 37.,\n",
            "         38., 39.],\n",
            "        [31., 30., 29., 28., 27., 26., 25., 24., 23., 22., 21., -1., -1., -1.,\n",
            "         23., 24., 25., 26., 27., 28., 29., 30., 31., 32., 33., 34., 35., 36.,\n",
            "         37., 38.],\n",
            "        [30., 29., 28., 27., 26., 25., 24., 23., 22., 21., 20., 19., 20., 21.,\n",
            "         22., 23., 24., 25., 26., 27., 28., 29., 30., 31., 32., 33., 34., 35.,\n",
            "         36., 37.],\n",
            "        [29., 28., 27., 26., 25., 24., 23., 22., 21., 20., 19., 18., 19., 20.,\n",
            "         21., 22., 23., 24., 25., 26., 27., 28., 29., 30., 31., 32., 33., 34.,\n",
            "         35., 36.],\n",
            "        [28., 27., 26., 25., 24., 23., 22., 21., 20., 19., 18., 17., 18., 19.,\n",
            "         20., 21., 22., 23., 24., 25., 26., 27., 28., 29., 30., 31., 32., 33.,\n",
            "         34., 35.],\n",
            "        [27., 26., 25., 24., 23., 22., 21., 20., 19., 18., 17., 16., 17., 18.,\n",
            "         19., 20., 21., 22., 23., 24., 25., 26., 27., 28., 29., 30., 31., 32.,\n",
            "         33., 34.],\n",
            "        [26., 25., 24., 23., 22., 21., 20., 19., 18., 17., 16., 15., 16., 17.,\n",
            "         18., 19., 20., 21., 22., 23., 24., 25., 26., 27., 28., 29., 30., 31.,\n",
            "         32., 33.],\n",
            "        [25., 24., 23., 22., 21., 20., 19., 18., 17., 16., 15., 14., 15., 16.,\n",
            "         17., 18., 19., 20., 21., 22., 23., 24., 25., 26., 27., 28., 29., 30.,\n",
            "         31., 32.],\n",
            "        [24., 23., 22., 21., 20., 19., 18., 17., 16., 15., 14., 13., 14., 15.,\n",
            "         16., 17., 18., 19., 20., 21., 22., 23., 24., 25., 26., 27., 28., 29.,\n",
            "         30., 31.],\n",
            "        [23., 22., 21., 20., 19., 18., 17., 16., 15., 14., 13., 12., 13., 14.,\n",
            "         15., 16., 17., 18., 19., 20., 21., 22., 23., 24., 25., 26., 27., 28.,\n",
            "         29., 30.],\n",
            "        [22., 21., 20., 19., 18., 17., 16., 15., 14., 13., 12., 11., 12., 13.,\n",
            "         14., 15., 16., 17., 18., 19., 20., 21., 22., 23., 24., 25., 26., 27.,\n",
            "         28., 29.],\n",
            "        [21., 20., 19., 18., 17., 16., 15., 14., 13., 12., 11., 10., 11., 12.,\n",
            "         13., 14., 15., 16., 17., 18., 19., 20., 21., 22., 23., 24., 25., 26.,\n",
            "         27., 28.],\n",
            "        [20., 19., 18., 17., 16., 15., 14., 13., 12., 11., 10.,  9., 10., 11.,\n",
            "         12., 13., 14., 15., 16., 17., 18., 19., 20., 21., 22., 23., 24., 25.,\n",
            "         26., 27.],\n",
            "        [19., 18., 17., 16., 15., 14., 13., 12., 11., 10.,  9.,  8.,  9., 10.,\n",
            "         11., 12., 13., 14., 15., 16., 17., 18., 19., 20., 21., 22., 23., 24.,\n",
            "         25., 26.],\n",
            "        [18., 17., 16., 15., 14., 13., 12., 11., 10.,  9.,  8.,  7.,  8.,  9.,\n",
            "         10., 11., 12., 13., 14., 15., 16., 17., 18., 19., 20., 21., 22., 23.,\n",
            "         24., 25.],\n",
            "        [17., 16., 15., 14., 13., 12., 11., 10.,  9.,  8.,  7.,  6.,  7.,  8.,\n",
            "          9., 10., 11., 12., 13., 14., 15., 16., 17., 18., 19., 20., 21., 22.,\n",
            "         23., 24.],\n",
            "        [18., 17., 16., 15., -1., -1., 10.,  9.,  8.,  7.,  6.,  5.,  6.,  7.,\n",
            "          8.,  9., 10., 11., 12., 13., 14., 15., 16., -1., -1., -1., -1., -1.,\n",
            "         -1., 25.],\n",
            "        [19., 18., -1., -1., -1., -1.,  9.,  8.,  7.,  6.,  5.,  4.,  5.,  6.,\n",
            "          7.,  8.,  9., 10., 11., 12., 13., 14., -1., -1., -1., -1., -1., -1.,\n",
            "         -1., -1.],\n",
            "        [20., -1., -1., -1., -1., -1., -1.,  7.,  6.,  5.,  4.,  3.,  4.,  5.,\n",
            "          6.,  7.,  8.,  9., 10., 11., 12., 13., -1., -1., -1., -1., -1., -1.,\n",
            "         -1., -1.],\n",
            "        [21., -1., -1., -1., -1., -1., -1.,  6.,  5.,  4.,  3.,  2.,  3.,  4.,\n",
            "          5.,  6.,  7.,  8.,  9., 10., 11., 12., -1., -1., -1., -1., -1., -1.,\n",
            "         -1., -1.],\n",
            "        [22., -1., -1., -1., -1., -1., -1., -1.,  4.,  3.,  2.,  1.,  2.,  3.,\n",
            "          4.,  5.,  6.,  7.,  8.,  9., 10., 11., -1., -1., -1., -1., -1., -1.,\n",
            "         -1., -1.],\n",
            "        [23., -1., -1., -1., -1., -1., -1., -1.,  3.,  2.,  1.,  0.,  1.,  2.,\n",
            "          3.,  4.,  5.,  6.,  7.,  8.,  9., 10., -1., -1., -1., -1., -1., -1.,\n",
            "         -1., -1.],\n",
            "        [24., -1., -1., -1., -1., -1., -1., -1., -1.,  3.,  2.,  1.,  2.,  3.,\n",
            "          4.,  5.,  6.,  7.,  8.,  9., 10., 11., -1., -1., -1., -1., -1., -1.,\n",
            "         -1., -1.],\n",
            "        [25., -1., -1., -1., -1., -1., -1., -1., -1.,  4.,  3.,  2.,  3.,  4.,\n",
            "          5.,  6.,  7.,  8.,  9., 10., 11., -1., -1., -1., -1., -1., -1., -1.,\n",
            "         -1., -1.]])\n"
          ]
        }
      ],
      "source": [
        "sample = nav_dataset[10]\n",
        "print(sample['y'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "id": "H2my5YA92P0w",
        "outputId": "e9364ae8-a5fd-4993-fcf9-8910a4211568"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.imshow(sample['x'][0], cmap='hot', interpolation='nearest')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "id": "Oi4BtSCH2cUF",
        "outputId": "9e4f870b-9a25-4b07-c504-ba86d9a92d7a"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.imshow(sample['x'][1], cmap='hot', interpolation='nearest')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "id": "87GTniEx1uwv",
        "outputId": "d6143e34-2a57-46f0-b8fd-2ebf8650c93c"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.imshow(sample['y'], cmap='hot', interpolation='nearest')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "1WpkQWBtf8AN"
      },
      "outputs": [],
      "source": [
        "# class NeuralNetwork1(nn.Module):\n",
        "  \n",
        "#   def __init__(self):\n",
        "#     super().__init__()\n",
        "#     self.conv1 = nn.Conv2d(2,8,1)\n",
        "#     self.conv2 = nn.Conv2d(8,64,1) #embedding size d = 64 apparently ? not sure how the two conv layers are actually connected\n",
        "#     self.flatten = nn.Flatten(start_dim = 2)\n",
        "\n",
        "#   def forward(self,x):\n",
        "#     x = F.relu(self.conv1(x))\n",
        "#     x = F.relu(self.conv2(x))\n",
        "#     x = self.flatten(x)\n",
        "\n",
        "#     #positional encoding \n",
        "#     #d = 64 , M^2 = 900\n",
        "#     #dry testing with fixed values\n",
        "    \n",
        "#     P = np.random.rand(64,900)\n",
        "\n",
        "#     for j in range(900):\n",
        "#       for i in range(32):\n",
        "#         P[2*i,j] = math.sin(j/(900**(2*i/64)))\n",
        "#       for i in range(32):\n",
        "#         P[2*i+1,j] = math.cos(j/(900**(2*i/64)))\n",
        "\n",
        "#     p = torch.from_numpy(P)\n",
        "#     p = p.to('cuda')\n",
        "#     x = x + p\n",
        "#     #I guess this handles the positional encoding part\n",
        "\n",
        "#     return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bx17hjkGCn3N",
        "outputId": "b888ebf3-4c91-4458-ebe0-401cf80e1df0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using cpu device\n"
          ]
        }
      ],
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f'Using {device} device')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Gwb82TonD6aS"
      },
      "outputs": [],
      "source": [
        "# model = NeuralNetwork1().to(device)\n",
        "# print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "pVqIo_jNFIWz"
      },
      "outputs": [],
      "source": [
        "# X = torch.rand(1,2,30,30, device=device)\n",
        "# tes1 = model(X)\n",
        "# print(tes1.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "dsys4McALJuc"
      },
      "outputs": [],
      "source": [
        "class NeuralNetwork2(nn.Module):\n",
        "  \n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    # LeNet()\n",
        "    self.conv1 = nn.Conv2d(in_channels = 2,out_channels = 8, kernel_size = 1)\n",
        "    # self.pool = nn.MaxPool2d(2,2)\n",
        "    self.conv2 = nn.Conv2d(8,64,1) #embedding size d = 64 apparently ? not sure how the two conv layers are actually connected\n",
        "    self.flatten = nn.Flatten(start_dim = 2)\n",
        "\n",
        "    # Positional Encoding\n",
        "    self.P = np.zeros((64,900))\n",
        "    for j in range(900):\n",
        "      for i in range(1,33):\n",
        "        self.P[2*i-2,j] = math.sin(j/(900**(2*i/64)))\n",
        "      for i in range(1,33):\n",
        "        self.P[2*i-1,j] = math.cos(j/(900**(2*i/64)))\n",
        "    self.P = torch.from_numpy(self.P.astype(np.float32))\n",
        "    self.P = self.P.to('cuda')\n",
        "    print(f'P nantest = {torch.isnan(self.P).any()}')\n",
        "    # Encoder\n",
        "    self.transformerlayer1 = nn.TransformerEncoderLayer(d_model=900, nhead=9, dim_feedforward=512, dropout=0, layer_norm_eps=1e-05, batch_first=False, norm_first=False, device=None, dtype=None)\n",
        "    self.transformerlayer2 = nn.TransformerEncoderLayer(d_model=900, nhead=9, dim_feedforward=512, dropout=0, layer_norm_eps=1e-05, batch_first=False, norm_first=False, device=None, dtype=None)\n",
        "    self.transformerlayer3 = nn.TransformerEncoderLayer(d_model=900, nhead=9, dim_feedforward=512, dropout=0, layer_norm_eps=1e-05, batch_first=False, norm_first=False, device=None, dtype=None)\n",
        "    self.transformerlayer4 = nn.TransformerEncoderLayer(d_model=900, nhead=9, dim_feedforward=512, dropout=0, layer_norm_eps=1e-05, batch_first=False, norm_first=False, device=None, dtype=None)\n",
        "    self.transformerlayer5 = nn.TransformerEncoderLayer(d_model=900, nhead=9, dim_feedforward=512, dropout=0, layer_norm_eps=1e-05, batch_first=False, norm_first=False, device=None, dtype=None)\n",
        "\n",
        "    # Decoder\n",
        "    self.fc1 = nn.Linear(64,1)\n",
        "    # self.fc1 = nn.Conv1d(in_channels = 64,out_channels=1,kernel_size=1)\n",
        "\n",
        "  def forward(self,x):\n",
        "    # print(f'x input nantest = {torch.isnan(x).any()}')\n",
        "    # print(f'x before conv = {x}')    \n",
        "    x = F.relu(self.conv1(x))\n",
        "    x = F.relu(self.conv2(x))\n",
        "    # print(f'x after conv = {x}')  \n",
        "    # print(f'x conv nantest = {torch.isnan(x).any()}')\n",
        "    x = self.flatten(x)\n",
        "\n",
        "    x = (x + self.P)\n",
        "    # print(f'x + positional encoding nantest = {torch.isnan(x).any()}')\n",
        "    x = self.transformerlayer1(x)\n",
        "    x = self.transformerlayer2(x)\n",
        "    x = self.transformerlayer3(x)\n",
        "    x = self.transformerlayer4(x)\n",
        "    x = self.transformerlayer5(x)\n",
        "    # print(f'x transformer nantest = {torch.isnan(x).any()}')\n",
        "    x = x.permute(0,2,1)\n",
        "    # x = self.fc1(x)\n",
        "    x = x.permute(0,2,1)\n",
        "\n",
        "    # print(f'x fc1 nantest = {torch.isnan(x).any()}')\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mj4EL_bVLJx5",
        "outputId": "50516dc0-eb54-4b28-f7e2-2b919f369730"
      },
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-faa55f2aadc9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNeuralNetwork2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-91226619a248>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mP\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m900\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mP\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mP\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mP\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mP\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'P nantest = {torch.isnan(self.P).any()}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;31m# Encoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    212\u001b[0m         \u001b[0;31m# This function throws if there's a driver initialization error, no GPUs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;31m# are found or any other error occurs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m         \u001b[0;31m# Some of the queued calls may reentrantly call _lazy_init();\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;31m# we need to just return without initializing in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: No CUDA GPUs are available"
          ]
        }
      ],
      "source": [
        "model = NeuralNetwork2().to(device)\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "1NG8ZnKzLJ04"
      },
      "outputs": [],
      "source": [
        "X = torch.rand(1,2,30,30, device=device)\n",
        "tes1 = model(X)\n",
        "print(tes1.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "yHZMfEqZLJ3-"
      },
      "outputs": [],
      "source": [
        "tes1 = torch.reshape(tes1,(30,30))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "TzNaMugFLJ69"
      },
      "outputs": [],
      "source": [
        "print(tes1.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "_bU4XZ_KLKB-"
      },
      "outputs": [],
      "source": [
        "tes1 = tes1.to('cpu').detach().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "pCgKAvaXLKFV"
      },
      "outputs": [],
      "source": [
        "plt.imshow(tes1, cmap='hot', interpolation='nearest')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "OoTmhLOm2kwY"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_dataloader = DataLoader(nav_dataset, batch_size=20, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "TLJAQVom7PqY"
      },
      "outputs": [],
      "source": [
        "def train_loop(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "\n",
        "    # with autograd.detect_anomaly():\n",
        "    for batch, sample in enumerate(dataloader):\n",
        "        # Compute prediction and loss\n",
        "        # sample = sample.to(device)\n",
        "        pred = model(sample['x'].to(device))\n",
        "        sample['y'] = sample['y'].to(device)\n",
        "        # print(pred.shape)\n",
        "        # print(sample['y'].shape)\n",
        "        # break\n",
        "        loss = loss_fn(torch.reshape(pred,(-1,30,30)), sample['y'])\n",
        "\n",
        "        # Backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            loss, current = loss.item(), batch * len(X)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "\n",
        "def test_loop(dataloader, model, loss_fn):\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    test_loss, correct = 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for sample in dataloader:\n",
        "            pred = model(sample['x'].to(device))\n",
        "            sample['y'] = sample['y'].to(device)\n",
        "            test_loss += loss_fn(torch.reshape(pred,(-1,30,30)), sample['y']).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "4xuAmoOV7ULc"
      },
      "outputs": [],
      "source": [
        "loss_fn = nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1)\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "scheduler = StepLR(optimizer, step_size=1, gamma=0.9)\n",
        "epochs = 40\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
        "    # test_loop(train_dataloader, model, loss_fn)\n",
        "    scheduler.step()\n",
        "print(\"Done!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ZEc7khTyPhWv"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), 'model_weights.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "qwumysStPhxy"
      },
      "outputs": [],
      "source": [
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Rx7545AEPtZ5"
      },
      "outputs": [],
      "source": [
        "sample = nav_dataset[10]\n",
        "sample['x'] = torch.reshape(sample['x'],(1,2,30,30))\n",
        "output = model(sample['x'].to(device))\n",
        "output = torch.reshape(output,(30,30))\n",
        "output = output.to('cpu').detach().numpy()\n",
        "\n",
        "plt.imshow(output, cmap='hot', interpolation='nearest')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "YgPF0HAdQREc"
      },
      "outputs": [],
      "source": [
        "plt.imshow(sample['y'], cmap='hot', interpolation='nearest')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "yXCN_XwiQeRI"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "network_test.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}